---
description: Команда тестирования студентов - генерация тестов на основе артефактов текущего и всех предыдущих этапов, интерактивный опрос и сохранение оценок
---

## Пользовательский ввод

```text
$ARGUMENTS
```

Ты **ОБЯЗАН** учитывать пользовательский ввод перед продолжением (если он не пустой).

## Описание

Эта команда **PLDF (Progressive Learning Development Framework)** позволяет студенту в любой момент пройти тестирование на основе артефактов текущего и всех предыдущих этапов проекта. Команда генерирует тесты трех типов (выбор одного варианта, выбор нескольких вариантов, свободный ответ), проводит интерактивный опрос и сохраняет детальную оценку с историей попыток.

## Предварительные условия

- Должен существовать хотя бы один артефакт проекта в `.pldf/`
- Если артефактов нет, предложи начать с этапа concept (`/pldf.concept`)

## Цель команды

Провести тестирование студента для оценки понимания материала:
- Проверить знание ключевых концепций из всех пройденных этапов
- Выявить слабые места в понимании
- Отследить прогресс по сравнению с предыдущими попытками
- Предоставить конструктивные рекомендации для улучшения

## Рабочий процесс

### 1. Определение текущего этапа

Определи текущий этап проекта на основе существующих артефактов в `.pldf/`:

- **concept**: если существует `.pldf/concept.md`
- **platforms**: если существует `.pldf/platforms.md`
- **design**: если существует `.pldf/ui-design.md` или `.pldf/ui-prototype/`
- **tech**: если существует `.pldf/tech-stack.md`
- **architecture**: если существует `.pldf/architecture.md`
- **plan**: если существует `.pldf/implementation-plan.md`
- **implement**: если существует код проекта и `.pldf/memory/progress.json` с шагами
- **review**: если существует `.pldf/review.md`

Текущий этап = последний созданный артефакт (самый поздний по последовательности этапов).

**Если артефактов нет:**
- Сообщи студенту, что для тестирования нужны артефакты проекта
- Предложи начать с этапа concept (`/pldf.concept`)

### 2. Загрузка всех существующих артефактов

Загрузи все существующие артефакты (текущего и всех предыдущих этапов):

- `.pldf/concept.md` (если существует)
- `.pldf/platforms.md` (если существует)
- `.pldf/ui-design.md` (если существует)
- `.pldf/ui-prototype/` (если существует)
- `.pldf/tech-stack.md` (если существует)
- `.pldf/tech-rationale.md` (если существует)
- `.pldf/architecture.md` (если существует)
- `.pldf/data-model.md` (если существует)
- `.pldf/contracts/` (если существует)
- `.pldf/implementation-plan.md` (если существует)
- `.pldf/memory/progress.json` (если существует)
- `.pldf/review.md` (если существует)
- `.pldf/project-context.md` (если существует)

### 3. Загрузка истории предыдущих попыток тестирования

**Если файл `.pldf/assessments.json` существует:**
- Загрузи файл `.pldf/assessments.json`
- Проанализируй предыдущие попытки:
  - Список всех заданных вопросов (по `id` вопросов)
  - Оценки по этапам (`scores.byStage`)
  - Оценки по темам (`scores.byTopic`)
  - Прогресс студента (`statistics.progress`)
  - Общее количество попыток (`statistics.totalAttempts`)
  - Средний балл (`statistics.averageScore`)

**Если файл `.pldf/assessments.json` не существует:**
- Это первая попытка тестирования
- Создай структуру из шаблона `.pldf/templates/assessment-template.json` (или создай базовую структуру, если шаблон недоступен)

### 4. Генерация тестов на основе артефактов и истории

Сгенерируй тесты (5-10 вопросов) на основе всех загруженных артефактов и истории попыток.

**Типы вопросов:**
- **Single choice** (выбор одного варианта) - 2-4 вопроса
- **Multiple choice** (выбор нескольких вариантов) - 1-3 вопроса
- **Free text** (свободный ответ) - 2-3 вопроса

**Распределение вопросов по этапам:**

**Если существует этап concept:**
- Вопросы о целевой аудитории, проблеме, функциях MVP, приоритизации (P1, P2, P3)
- Примеры тем: `целевая_аудитория`, `проблема`, `функции_mvp`, `приоритизация`

**Если существует этап platforms:**
- Вопросы о выбранных платформах, обосновании выбора, кроссплатформенных решениях
- Примеры тем: `выбор_платформ`, `обоснование_платформ`, `кроссплатформенность`

**Если существует этап design:**
- Вопросы о пользовательских потоках, данных на экранах, паттернах UI
- Примеры тем: `пользовательские_потоки`, `данные_экранов`, `ui_паттерны`, `навигация`

**Если существует этап tech:**
- Вопросы о выборе технологий, обосновании, альтернативах, компромиссах
- Примеры тем: `выбор_технологий`, `обоснование_выбора`, `альтернативы`, `компромиссы`

**Если существует этап architecture:**
- Вопросы о структуре проекта, модели данных, API контрактах, паттернах
- Примеры тем: `структура_проекта`, `модель_данных`, `api_контракты`, `архитектурные_паттерны`

**Если существует этап plan:**
- Вопросы о логике разбивки, зависимостях, валидации шагов
- Примеры тем: `разбивка_на_шаги`, `зависимости`, `валидация`, `планирование`

**Если существует этап implement:**
- Вопросы о реализованном коде, связях между шагами, валидации
- Примеры тем: `реализация`, `связи_шагов`, `валидация_кода`, `тестирование`

**Если существует этап review:**
- Вопросы о сильных/слабых сторонах, улучшениях, рефлексии
- Примеры тем: `анализ`, `улучшения`, `рефлексия`, `best_practices`

**Распределение вопросов:**
- Минимум 1-2 вопроса на каждый существующий этап
- Больше вопросов на текущий этап (2-3 вопроса)
- Общее количество вопросов: 15-20 (зависит от количества пройденных этапов)
- Вопросы должны проверять понимание связей между этапами (например, как концепция повлияла на дизайн, как дизайн повлиял на архитектуру)

**Учет предыдущих попыток при генерации вопросов:**

**Если это первая попытка:**
- Генерируй базовые вопросы по всем этапам
- Распределяй вопросы равномерно по этапам
- Используй стандартную сложность вопросов

**Если это не первая попытка:**
- **Избегай повторения**: не задавай вопросы с теми же `id`, что были в предыдущих попытках (или задавай их в другой формулировке, если необходимо проверить прогресс)
- **Фокус на слабых местах**: больше вопросов по темам/этапам, где были низкие оценки в предыдущих попытках (оценка < 60%)
- **Развитие сильных сторон**: предлагай более сложные и глубокие вопросы по темам, где студент показал хорошие результаты (оценка > 80%) - проверка более глубокого понимания, связи с другими темами
- **Проверка прогресса**: если студент улучшил оценки по теме, задавай вопросы следующего уровня сложности
- **Выявление пробелов**: если оценки по теме остаются низкими, задавай вопросы с разных углов, чтобы понять причину непонимания
- **Межэтапные связи**: если студент хорошо усвоил отдельные этапы, задавай больше вопросов о связях между этапами

**Формат вопроса:**

Каждый вопрос должен иметь следующую структуру:
```json
{
  "id": "q-XXX-YYY",
  "type": "single_choice|multiple_choice|free_text",
  "text": "Текст вопроса",
  "stage": "concept|platforms|design|tech|architecture|plan|implement|review",
  "topic": "название_темы",
  "options": ["вариант 1", "вариант 2", ...], // только для single_choice и multiple_choice
  "correctAnswer": "...", // правильный ответ
  "maxScore": 1.0
}
```

Где `XXX` - номер попытки, `YYY` - порядковый номер вопроса.

### 5. Интерактивный опрос студента

Проведи интерактивный опрос:

1. **Приветствие и объяснение:**
   - Поприветствуй студента
   - Объясни, что будет тестирование на основе артефактов проекта
   - Укажи количество вопросов
   - Если это не первая попытка, упомяни, что будут учтены предыдущие результаты

2. **Задавай вопросы по очереди:**
   - Покажи вопрос с номером (например, "Вопрос 1 из 8")
   - Для single choice и multiple choice: покажи все варианты ответов с буквами/номерами
   - Для free text: объясни, что нужен развернутый ответ
   - Дождись ответа студента
   - **НЕ** давай обратную связь сразу после ответа (сохрани ответ для оценки)
   - Переходи к следующему вопросу

3. **После всех вопросов:**
   - Поблагодари студента за прохождение теста
   - Сообщи, что сейчас будет оценка ответов

### 6. Оценка ответов на основе артефактов

Оцени каждый ответ студента на основе артефактов проекта:

**Для single choice:**
- Если выбран правильный вариант → `score = maxScore` (обычно 1.0)
- Если выбран неправильный вариант → `score = 0`
- Сохрани `studentAnswer` и `score` для вопроса

**Для multiple choice:**
- Проверь все выбранные варианты
- Если все правильные варианты выбраны и неправильные не выбраны → `score = maxScore`
- Если выбраны не все правильные или выбраны неправильные → частичные баллы:
  - `score = (количество_правильных_выбранных / общее_количество_правильных) * maxScore`
- Сохрани `studentAnswer` (массив выбранных вариантов) и `score` для вопроса

**Для free text:**
- Проведи семантический анализ ответа на основе артефактов
- Проверь наличие ключевых концепций из артефактов
- Оцени понимание темы:
  - **Отлично (0.9-1.0)**: ответ содержит все ключевые концепции, демонстрирует глубокое понимание
  - **Хорошо (0.7-0.89)**: ответ содержит большинство ключевых концепций, демонстрирует хорошее понимание
  - **Удовлетворительно (0.5-0.69)**: ответ содержит некоторые ключевые концепции, демонстрирует базовое понимание
  - **Неудовлетворительно (0-0.49)**: ответ не содержит ключевых концепций или не демонстрирует понимание
- Сохрани `studentAnswer` (текст ответа) и `score` для вопроса

**Вычисление оценок:**
- Для каждого вопроса: `score` и `maxScore`
- Для каждого этапа: средняя оценка по вопросам этого этапа
- Для каждой темы: средняя оценка по вопросам этой темы
- Общий балл: `overallScore = (сумма всех score / сумма всех maxScore) * 100`

### 7. Генерация детального отчета

Создай детальный отчет с разбивкой по темам и рекомендациями:

**Структура отчета:**

1. **Общий балл:**
   - Процент правильных ответов (`overallScore`)
   - Оценка в текстовом формате:
     - 90-100%: Отлично
     - 75-89%: Хорошо
     - 60-74%: Удовлетворительно
     - <60%: Требуется повторение

2. **Разбивка по этапам:**
   - Для каждого этапа: средняя оценка, количество вопросов
   - Какие этапы усвоены хорошо (оценка > 75%)
   - Какие этапы требуют повторения (оценка < 60%)

3. **Разбивка по темам:**
   - Для каждой темы: средняя оценка, количество вопросов
   - Темы с высокими оценками
   - Темы с низкими оценками

4. **Конкретные рекомендации:**
   - Для каждого этапа с низкой оценкой: что нужно изучить, какие артефакты пересмотреть
   - Для каждой темы с низкой оценкой: конкретные рекомендации по улучшению понимания

5. **Сравнение с предыдущими попытками** (если есть):
   - Прогресс по каждой теме (улучшилось/ухудшилось/без изменений)
   - Темы, которые требуют дополнительного внимания
   - Темы, где студент показывает стабильный прогресс
   - Улучшение общего балла (если есть)

6. **Рекомендации для следующего тестирования:**
   - Какие темы стоит изучить глубже перед следующим тестом
   - Какие вопросы будут заданы в следующий раз (на основе слабых мест)

### 8. Сохранение результатов в файл оценок

Сохрани результаты тестирования в `.pldf/assessments.json`:

1. **Создай новую запись assessment:**
   ```json
   {
     "id": "assessment-XXX", // где XXX - порядковый номер попытки
     "date": "YYYY-MM-DD", // текущая дата
     "currentStage": "название_текущего_этапа",
     "questions": [...], // массив всех вопросов с ответами и оценками
     "scores": {
       "byStage": {
         "concept": 85.5,
         "design": 72.0,
         ...
       },
       "byTopic": {
         "целевая_аудитория": 90.0,
         "проблема": 75.0,
         ...
       }
     },
     "overallScore": 82.5,
     "detailedReport": {...} // детальный отчет в структурированном виде
   }
   ```

2. **Обнови статистику:**
   - `statistics.totalAttempts` - увеличить на 1
   - `statistics.averageScore` - пересчитать средний балл
   - `statistics.byStage` - обновить средние оценки по этапам
   - `statistics.byTopic` - обновить средние оценки по темам
   - `statistics.progress` - проанализировать прогресс:
     - `improvingTopics` - темы, где оценки улучшились
     - `stagnantTopics` - темы, где оценки не изменились
     - `decliningTopics` - темы, где оценки ухудшились

3. **Сохрани файл:**
   - Если файл не существует, создай его из шаблона
   - Добавь новую запись в `assessments`
   - Обнови `statistics`
   - Сохрани в `.pldf/assessments.json`

### 9. Вывод результатов студенту

Выведи результаты тестирования студенту:

1. **Краткое резюме:**
   - Общий балл и оценка
   - Количество правильных ответов из общего количества

2. **Детальный отчет:**
   - Разбивка по этапам
   - Разбивка по темам
   - Конкретные рекомендации

3. **Сравнение с предыдущими попытками** (если есть):
   - Прогресс по темам
   - Улучшение общего балла

4. **Рекомендации:**
   - Что нужно изучить перед следующим тестом
   - Какие артефакты пересмотреть

5. **Путь к файлу:**
   - Укажи путь к `.pldf/assessments.json` для просмотра истории

## Правила

- **БУДЬ КОНСТРУКТИВНЫМ** - давай конкретные рекомендации, а не только оценки
- **ОБЪЯСНЯЙ ОШИБКИ** - объясняй, почему ответ неправильный и что нужно изучить
- **ОТСЛЕЖИВАЙ ПРОГРЕСС** - сравнивай с предыдущими попытками и показывай улучшения
- **АДАПТИРУЙ ВОПРОСЫ** - учитывай историю попыток при генерации вопросов
- **НЕ ПОВТОРЯЙ ВОПРОСЫ** - избегай повторения уже заданных вопросов (или формулируй по-другому)

## Выходные артефакты

- `.pldf/assessments.json` - файл с историей всех попыток тестирования и статистикой

## Примеры использования

```
/pldf.test
```

Команда автоматически определит текущий этап, загрузит все артефакты и проведет тестирование.

## Подсказки и помощь

### Когда использовать

- После завершения любого этапа для проверки понимания
- Перед переходом к следующему этапу для закрепления знаний
- В любой момент для оценки текущего уровня понимания

### Типичные вопросы

**Если студент получил низкий балл:**
- Предложи пересмотреть соответствующие артефакты
- Укажи конкретные разделы для изучения
- Предложи пройти тест еще раз после изучения материала

**Если студент получил высокий балл:**
- Поздравь с хорошим результатом
- Предложи более сложные вопросы в следующий раз
- Поощри продолжение работы над проектом

